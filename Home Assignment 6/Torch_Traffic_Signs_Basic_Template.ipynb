{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "diBOWISLz3fV"
   },
   "source": [
    "# Basic CNN for traffic sign recognition\n",
    "## Christian Igel, 2022\n",
    "\n",
    "This notebook provides a template for a small CNN for the German Traffic Sign Recognition Benchmark. The data is described in:\n",
    "\n",
    "Johannes Stallkamp, Marc Schlipsing, Jan Salmen, and Christian Igel. Man vs. Computer: Benchmarking Machine Learning Algorithms for Traffic Sign Recognition. *Neural Networks* **32**, pp. 323-332, 2012\n",
    "\n",
    "This notebook is a template, without modification the model does not even come close to the state-of-the-art. \n",
    "\n",
    "Please [contact me](mailto:igel@diku.dk) if you have suggestions for improving the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hh3zJV20NKO"
   },
   "source": [
    "Do the imports first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_DEmCw_O1N4m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.datasets.utils import download_url, extract_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCmU86Yn0VW0"
   },
   "source": [
    "Check if a GPU is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ypjWR1XCKZzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if gpu else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krrag66A0Y7n"
   },
   "source": [
    "The GTSRB data wrapped in a `Dataset`. This is implemented in the file `GTSRBTrafficSigns.py`. Let's import the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uKBCYtfv1YNC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision.datasets.utils import download_url, extract_archive\n",
    "\n",
    "class GTSRBTrafficSigns(Dataset):\n",
    "  \"\"\" GTSRB data set \"\"\"\n",
    "\n",
    "  def __init__(self, root = './', url = 'https://sid.erda.dk/share_redirect/EB0rrpZwuI', filename='EB0rrpZwuI.zip', train=True, force_download=False, crop_size=28): \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    root: str\n",
    "        Parent directory\n",
    "    url: str\n",
    "        URL of data set\n",
    "    filename: str\n",
    "        Filename of the zipped data\n",
    "    train: bool\n",
    "        Indicating whether training or test data should be considered\n",
    "    force_download: bool\n",
    "        Download data from server even if a local copy is detected\n",
    "    crop_size: int\n",
    "        Height and width of the input image \n",
    "    \"\"\"\n",
    "    self.img_height  = 32  \n",
    "    self.img_width   = self.img_height\n",
    "    self.img_height_crop = crop_size  \n",
    "    self.img_width_crop  = self.img_height_crop\n",
    "\n",
    "    self.train = train\n",
    "    archive = os.path.join(root, filename)\n",
    "\n",
    "    if self.train:\n",
    "      self.data_folder = os.path.join(root, 'GTSRB/train')\n",
    "    else:\n",
    "      self.data_folder = os.path.join(root, 'GTSRB/test')\n",
    "\n",
    "    if (not os.path.exists(self.data_folder)) or force_download:\n",
    "      download_url(url, root, filename)\n",
    "      extract_archive(archive, root, False)\n",
    "    else:\n",
    "      print('Using existing', self.data_folder)\n",
    "\n",
    "    self.dataset_train = datasets.ImageFolder(self.data_folder)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      image, label = self.dataset_train.__getitem__(index)\n",
    "      image = transforms.Resize((self.img_width,self.img_height))(image)\n",
    "      \n",
    "      # These transformations just serve as examples\n",
    "      if self.train:\n",
    "        image = transforms.RandomAffine((-5,5))(image)\n",
    "        image = transforms.RandomCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "        image = transforms.ColorJitter(0.8, contrast = 0.4)(image)\n",
    "        if label in [11, 12, 13, 17, 18, 26, 30, 35]:\n",
    "          image = transforms.RandomHorizontalFlip(p=0.5)(image)\n",
    "      else:\n",
    "        image = transforms.CenterCrop((self.img_width_crop, self.img_height_crop))(image)\n",
    "\n",
    "      image = transforms.ToTensor()(image)\n",
    "\n",
    "      return image, label\n",
    "\n",
    "  def __len__(self):\n",
    "      return self.dataset_train.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kxLuzusI3wgY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing ./GTSRB/train\n"
     ]
    }
   ],
   "source": [
    "dataset_train = GTSRBTrafficSigns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEoOq0fR0shZ"
   },
   "source": [
    "Define the data loader for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cMvy6psj4Da3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marku\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "generator_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training patterns: 37126\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training patterns:\", dataset_train.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4EPJdLb0yrN"
   },
   "source": [
    "Let's visualize some input images. This visualization is very important, among others to verify that the data augmentation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g3bfL8fr4oby"
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(generator_train)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYoceXxa1LgG"
   },
   "source": [
    "Let's look at each image in the batch with its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rr9Zq9-O_TmF"
   },
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "  imshow(images[i])\n",
    "  print(labels[i].item(), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCAWy9O-19t8"
   },
   "source": [
    "Define the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTehyjtbAbUl"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, img_size=28):\n",
    "        super(Net, self).__init__()\n",
    "        conv1 = nn.Conv2d(3, 64, 5)\n",
    "        pool1 = nn.MaxPool2d(2, 2)\n",
    "        conv2 = nn.Conv2d(64, 64, 5)\n",
    "        pool2 = nn.MaxPool2d(2, 2)\n",
    "        fc2 = nn.Linear(64 * 4 * 4, 43)\n",
    "        self.conv1 = conv1\n",
    "        self.pool1 = pool1\n",
    "        self.conv2 = conv2\n",
    "        self.pool2 = pool2\n",
    "        self.fc2 = fc2\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdQ3MDpY2QOJ"
   },
   "source": [
    "Instantiate the neural network and potentially move it to GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k20BZnTt2N1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=43, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "if(gpu):\n",
    "  net.to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYFQ3dJf2a7q"
   },
   "source": [
    "Define loss and optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4zMyMCTAQb4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln380IT62sj-"
   },
   "source": [
    "These lines can be used to continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un0R8p_N2gPX"
   },
   "outputs": [],
   "source": [
    "cont = False\n",
    "if cont:\n",
    "  net.load_state_dict(torch.load('traffic_simple'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMaDlTva28hU"
   },
   "source": [
    "Do the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzaIsMCVJQK6"
   },
   "outputs": [],
   "source": [
    "no_epochs = 200\n",
    "for epoch in range(no_epochs):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(generator_train, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        if (gpu):\n",
    "          inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        else:\n",
    "          inputs, labels = data\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        reporting_interval = 100\n",
    "        running_loss += loss.item()\n",
    "        if i % reporting_interval == reporting_interval-1:  # Print every reporting_interval mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / reporting_interval))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aN5_Zt8V3GFj"
   },
   "source": [
    "Evaluate on test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZueXQjDVJhAj"
   },
   "outputs": [],
   "source": [
    "dataset_test = GTSRBTrafficSigns(train=False)\n",
    "generator_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "print(\"Number of test patterns:\", dataset_test.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZueXQjDVJhAj"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in generator_test:\n",
    "        if (gpu):\n",
    "          images, labels = data[0].to(device), data[1].to(device)\n",
    "        else:\n",
    "          images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWyvZX0y3IzO"
   },
   "source": [
    "Save network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQ_hik0qMdEx"
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'traffic_simple')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Torch Traffic Signs Basic Template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
